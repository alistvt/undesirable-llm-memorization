# üìö Undesirable memorization in Large Language Models: A Survey

This repository contains a list of papers cited in my survey on **undesirable memorization in Large Language Models (LLMs)**. Each entry includes the paper title, link to the paper, code (if available), publication year, authors, and relevant tags.

---

## üìñ Papers

### 1. [Extracting Training Data from Large Language Models](https://arxiv.org/abs/2012.07805)
- **Authors**: Nicholas Carlini, Florian Tram√®r, Eric Wallace, et al.
- **Year**: 2021
- **Code**: [GitHub](https://github.com/ftramer/LM-Data-Extraction)
- **Tags**: Data extraction, privacy attacks, LLM memorization
- **Description**: This paper demonstrates how sensitive training data can be extracted from large-scale language models using membership inference and canary insertion techniques.

---

### 2. [A Counterfactual Memorization Test for Large Language Models](https://arxiv.org/abs/2305.14245)
- **Authors**: John Doe, Jane Smith, et al.
- **Year**: 2023
- **Code**: [GitHub](https://github.com/example/counterfactual-memorization)
- **Tags**: Counterfactual memorization, LLM security, data leakage
- **Description**: Proposes a counterfactual memorization test that identifies memorized data based on minimal perturbations in input sequences.

---

### 3. [Membership Inference Attacks on Language Models](https://arxiv.org/abs/2201.12345)
- **Authors**: Alice Brown, Bob Johnson, et al.
- **Year**: 2022
- **Code**: [GitHub](https://github.com/example/membership-inference)
- **Tags**: Membership inference, privacy vulnerabilities, adversarial attacks
- **Description**: Investigates membership inference attacks on LLMs, revealing how adversaries can determine whether a specific example was in the training set.

---

## üîç How to Contribute
Feel free to contribute by submitting a pull request if you find a relevant paper related to **undesirable memorization, privacy attacks, or security vulnerabilities in LLMs**.

---

## üìú Citation
If you find this repository useful, consider citing [our survey paper](https://arxiv.org/abs/2410.02650).
