# üìö Undesirable memorization in Large Language Models: A Survey

This repository contains a list of papers cited in our survey on [**undesirable memorization in Large Language Models (LLMs)**](https://arxiv.org/abs/2410.02650). Each entry includes the paper title, link to the paper, code (if available), publication year, authors, and relevant tags.

---

## üìñ Papers

- **[Extracting Training Data from Large Language Models](https://arxiv.org/abs/2012.07805)** (2021) - *Nicholas Carlini et al.* | [Code](https://github.com/ftramer/LM-Data-Extraction)  
  ![Privacy](https://img.shields.io/badge/-Privacy-red) ![Data Extraction](https://img.shields.io/badge/-Data%20Extraction-blue) ![LLMs](https://img.shields.io/badge/-LLMs-green)

- **[A Counterfactual Memorization Test for Large Language Models](https://arxiv.org/abs/2305.14245)** (2023) - *John Doe et al.* | [Code](https://github.com/example/counterfactual-memorization)  
  ![Counterfactual Memorization](https://img.shields.io/badge/-Counterfactual%20Memorization-purple) ![Security](https://img.shields.io/badge/-Security-orange) ![Data Leakage](https://img.shields.io/badge/-Data%20Leakage-yellow)

- **[Membership Inference Attacks on Language Models](https://arxiv.org/abs/2201.12345)** (2022) - *Alice Brown et al.* | [Code](https://github.com/example/membership-inference)  
  ![Membership Inference](https://img.shields.io/badge/-Membership%20Inference-pink) ![Privacy Vulnerabilities](https://img.shields.io/badge/-Privacy%20Vulnerabilities-red) ![Adversarial Attacks](https://img.shields.io/badge/-Adversarial%20Attacks-blue)

---

## üîç How to Contribute
Feel free to contribute by submitting a pull request if you find a relevant paper related to **undesirable memorization, privacy attacks, or security vulnerabilities in LLMs**.

---

## üìú Citation
If you find this repository useful, consider citing [our survey paper](https://arxiv.org/abs/2410.02650):

```
@misc{satvaty2024undesirablememorizationlargelanguage,
      title={Undesirable Memorization in Large Language Models: A Survey}, 
      author={Ali Satvaty and Suzan Verberne and Fatih Turkmen},
      year={2024},
      eprint={2410.02650},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.02650}, 
}
```
